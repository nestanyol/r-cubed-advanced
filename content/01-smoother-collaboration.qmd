# Smoother project-based collaboration {#smoother-collaboration}

```{r}
# zip from previous directory?
# proj_dir <- zip()
```

{{< include /includes/_wip.qmd >}}

Many of you probably work largely and mostly consistently on your own,
but as your move through your career (in academia or industry), you will
need to and maybe also want to *directly
collaborate*[^01-smoother-collaboration-1] a lot more with others.
Different types of collaboration (e.g. meetings, brainstorming,
real-time co-writing) form the basis for almost all research-based work
and probably most non-research-based work.

[^01-smoother-collaboration-1]: Collaborate here meaning directly
    contributing to a shared project, rather than discussed or planning
    based collaborations (and definitely not emailing-files-around
    collaboration).

More direct collaboration on a project quickly becomes unmanageable when
using traditional academic "workflows" (emailing around). That's when
you need to start using tools designed for collaboration, like Git. But
Git is just the starting point. There are many many other things to
consider for workflows and processes to effectively collaborate with
others. This session is about making use of more automated ways of
structuring data analysis projects to ease collaboration.

## Learning objectives

The overall objective for this session is to:

1.  Identify potential actions to streamline collaboration on a data
    analysis project and create projects that apply many of these
    actions using R.

More specific objectives are to:

1.  Explain what project-level R dependency management is, what a
    "project environment" is, and why these concepts are important to
    consider in collaborative and reproducible analyses.
2.  Describe the difference between "workflow dependencies" and "build
    dependencies".
3.  Apply functions in the `{renv}` and `{usethis}` R packages to
    implement these dependency management concepts.
4.  Explain the role that following a style guide has on building a
    common approach to reading (and writing) R code, and thus improve
    project-level collaboration.
5.  Use `{styler}`, `{lintr}`, and RStudio's canonical markdown mode to
    programmatically check and apply style guides to your project files.

## Project-level R dependency management

> Note: This first session is more conceptual and is heavier on the
> reading and explanation, but is important for the next sessions.

One of the first things to consider when working collaboratively on a
data analysis project (and probably other types of projects too) is what
software to use for your project. This starts out at the highest level:
Are you using R or some other software for the analysis? Since this is
an R course, so we're assuming the software will be R! ðŸ˜œ

The next consideration is which packages do you need that will
ultimately be the ones your project depends on to get the results that
you find. When working collaboratively with others, and yourself several
months in the future, you need some way of knowing how to easily and
quickly install or update these package dependencies.

Let's start with the `AdvancedR3` project that uses the `lipidomics`. We
have code in the `data-raw/nmr-omics.R` file that uses some packages.
Let's assume that your project will be more complex than this and that
you will eventually need some collaborators to contribute who are
experts in, for instance metabolomics data processing and in statistical
analysis of high-dimensional data. You know you will end up needing to
use other packages. You also know that you all need some way of tracking
which packages are used so that when others join and contribute to the
project, they can as seamlessly as possible install or update the
packages your data analysis project needs. There are a few ways of
"tracking" package dependencies.

1.  The simplest, but most primitive way is to always make sure to use
    `library()` at the top of each R script for each package that the R
    script uses.

    -   Advantage:

        -   This is the easiest to conceptually understand and to use.

    -   Disadvantages:

        -   It doesn't track project-level dependencies very well, since
            multiple scripts probably use similar packages across them.
            Which means you can't easily and quickly install or update
            all the packages your project uses, since you will probably
            have to go through each R script manually and install each
            package manually. You might have seen some scripts with code
            that looks like this at the top:

            ``` r
            if (!require("packagename")) {
              install.packages("packagename")
            }
            ```

            What this code does is check if a package exists, if not,
            than it installs it. But! This is not an optimal methods to
            track packages because `require()` won't load the package if
            it doesn't find it. Which means you would have to re-run the
            script probably a few times. Plus, sometimes you may need to
            restart the R session after installing a package in order
            for R to detect it probably.

        -   It doesn't track the *versions* of the packages your project
            depends on, so if a package gets updated and it breaks
            something, you might not be able to figure out how to
            quickly fix that issue, especially for those deadline
            crunches.

2.  The most common form, at least based on R packages and projects
    found on GitHub, is making use of the `DESCRIPTION` file and
    `usethis::use_package()` to track which package is used for a
    project or not. We covered this style of dependency in the
    [intermediate
    course](https://r-cubed-intermediate.rostools.org/dry-functions.html#continuing-the-workflow).
    We will also use this approach during this course, but expand a lot
    more on it.

    -   Advantages:

        -   Relatively easy to conceptually understand, since you can
            directly view the packages your project needs by opening the
            `DESCRIPTION` file and looking at the contents.

        -   Because it is widely used, there are many processes already
            built around making use of tracking dependencies this way.
            For instance, you need to track package dependencies when
            creating R packages.

        -   Installing packages is as easy as opening the project and
            running `remotes::install_deps()` in the Console, which will
            install all the packages listed in the `DESCRIPTION` file.

        -   Adding packages that you need is as easy as writing
            `usethis::use_package("packagename")` in the Console.

    -   Disadvantages:

        -   Like the previous method, it doesn't easily keep track of
            the versions of the packages you are using.

        -   Your project might still rely on a package that is installed
            on *your* computer and that influences your project, but
            that might not be obvious as a dependency or that you forgot
            to include.

Before continuing to the exercise, we need to make sure to add and
comment all the files from the project into the Git history. Open the
Git interface by either typing `Ctrl-Shift-M` or by going to the Git
pane and clicking the "Commit" button.

## Exercise: Add packages from the data processing script

> Time: \~10 minutes.

Since the `DESCRIPTION` file will be used later on for the more formal
dependency management, let's get it updated with the packages we are
using in the `data-raw/nmr-omics.R` script. Open that file and complete
these tasks:

1.  Look for package dependencies that are declared with `library()` and
    `::`.
2.  Use `?usethis::use_package` to review how to use this function.
3.  In the Console, run `usethis::use_package()` for each package you
    find in `data-raw/nmr-omics.R` (from 1. above).
4.  Once done, open the Git interface (`Ctrl-Shift-M` or go to the Git
    Pane and click the "Commit" button). What has been changed? Commit
    those changes to the Git history.

```{r solution-add-processing-packages}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are really struggling or are out of time for the exercise."
#| purl: true
usethis::use_package("readxl")
usethis::use_package("dplyr")
usethis::use_package("tidyr")
usethis::use_package("here")
usethis::use_package("fs")
usethis::use_package("usethis")
```

```{r exec-only-add-packages}
#| include: false
#| eval: false
# Used to build the underlying project for the book
usethis::with_project(
  proj_dir,
  {
    usethis::use_package("readxl")
    usethis::use_package("dplyr")
    usethis::use_package("tidyr")
    usethis::use_package("here")
    usethis::use_package("fs")
    usethis::use_package("usethis")
  }
)
```

## Formal dependency management

While the approach of managing package dependencies through the
`DESCRIPTION` file is quite powerful, it has the major disadvantage of
not keeping track of the *version* of each of your packages. So instead
we are going to use a package dedicated to handling project
dependencies, called `{renv}`.

`{renv}` is a package that manages package dependencies in a project by,
in simple terms, creating a project-specific R "library". You might
think of `library()` when you hear R library, and you aren't completely
wrong. When you call, for instance, `library("usethis")`, R looks for
the package `{usethis}` in your computer's "library" of R packages. This
library can be found by running this function:

```{r libpaths}
.libPaths()
```

Those file paths are where all R packages are installed to. If there is
more than one path, R checks the first before continuing to the next. So
than what `{renv}` does is create another file path for R packages to be
installed instead within the project. This isn't completely what it
does, since there are a lot of very technical details to what `{renv}`
does internally, but this is the basic concept.

In the end, this makes your project relatively self-contained in its
package dependencies.

-   Advantages:

    -   Installing all packages necessary for your project is as easy as
        running `renv::restore()`. `{renv}` even gives you helpful tips
        and instructions when things go wrong or if something is
        missing.

    -   *Every* package, including the packages that your packages
        depend on, have their version tracked. So if a package gets
        updated on CRAN, it doesn't affect you *until you choose*, when
        you use `renv::update()`. If a package update breaks your code
        and you have a deadline, you can easily go back to the older
        versions of the packages.

    -   Because your project is now self-contained with its own R
        library, it becomes very obvious (through errors) when you might
        be missing some other dependency because your code wouldn't run
        until you install or fix that package dependency.

    -   From a reproducibility point of view, as long as your project is
        tracked by `{renv}`, it's easier to independently have your data
        analysis be reproduced and verified.

-   Disadvantages:

    -   It takes a fair amount of learning to conceptually understand
        what is going on.

    -   When there are issues that come up, it can be difficult to
        figure them out.

    -   Because *all* packages, including those packages that your
        packages depend on, are installed within your project,
        installation times can sometimes be a bit long.

::: aside
It's sometimes very annoying to debug these "virtual environments". But
thankfully you can turn it off with `renv::deactivate()`! It still is
worth it to start considering and accounting for how your dependencies
might influence your project results and collaboration.
:::

Let's start using `{renv}` in our `AdvancedR3` project. In the Console,
type out:

```{r renv-init}
#| eval: false
#| purl: true
renv::init()
```

The function `renv::init()` initializes the project to begin being
managed by `{renv}`. It will ask a series of questions and then will
install all the packages detected in the project. It adds several files
to the project:

```{r show-created-files}
#| echo: false
fs::dir_tree(regexp = "\\.Rprofile|renv", all = TRUE, recurse = 1)
```

-   `.Rprofile`: This is the file that `{renv}` uses to build up its
    machinery. With an `.Rprofile` within the project folder, we can
    create a "project environment". By having this project environment
    that is (mostly) self-contained, it allows us to be a bit closer to
    having a fully reproducible analysis and it makes it easier to
    collaborate together, since we all than share the same project
    setup.

-   `renv.lock`: This contains all the information about the packages
    your project depends on, including where it was installed from (CRAN
    or GitHub for example), what the version number is, and more. This
    is like a supercharged version of the `DESCRIPTION` file.

-   `renv/`: This folder contains several other files that make up the
    machinery of `{renv}`. For instance, there is the `library/` folder
    that contains all the R packages necessary for the project. Then
    there's the `activate.R` script and `settings.dcf` file that both
    work to management the dependencies, like installing, updating, and
    removing.

**Before we continue, let's commit the new files to the Git history**.

The general workflow for using `{renv}` while working on your project is
described in more detail on the [Introduction to
renv](https://rstudio.github.io/renv/articles/renv.html#workflow)
webpage. However, unlike the general workflow, we also want to continue
using the `DESCRIPTION` file. That's because a lot of tools and
workflows exist that make use of it, so we want to remain compatible
with them.

As we work on the project and realize we need to use a specific package,
we would normally use `install.packages()` and then add `library()` to
the script or R Markdown file. Later on, we'd eventually run
`renv::snapshot()` to update the `renv.lock` file with the new packages
we've installed. `renv::snapshot()` as well as `renv::init()` usually
rely on "implicit" dependencies, meaning `{renv}` will search throughout
the project for any packages used and add them to the `renv.lock` file.

However, in science, we want to be more explicit rather than implicit.
The way `{renv}` explicitly adds to the `renv.lock` file is by only
scanning the `DESCRIPTION` file. In order for `{renv}` to always do
this, we need to set an option for it. This option needs to be added to
the project's `.Rprofile` file.

We can quickly open this with:

```{r open-rprofile-first-time}
#| eval: false
#| purl: true
usethis::edit_r_profile("project")
```

Next, at the top of the file, add this code:

```{r snapshot-settings}
#| eval: false
#| purl: true
options(renv.settings.snapshot.type = "explicit",
        renv.config.auto.snapshot = TRUE)
```

These two options make it so that whenever you add a package with
`usethis::use_package()` or `install.packages()`, `{renv}` will always
run `renv::snapshot()` and the snapshot explicitly only look at the
`DESCRIPTION` file. Let's restart the R session so that the `.Rprofile`
changes get activated.

Now our `{renv}` workflow will largely be automated for us, as long as
we do `usethis::use_package()`. If we ever ever return to a project or
collaborate on a project that uses `{renv}`, we can install all the
necessary packages with:

```{r renv-restore}
#| eval: false
renv::restore()
```

And if we need to update packages, we use:

```{r renv-update}
#| eval: false
renv::update()
```

*Sometimes*, working with `{renv}` can get annoying and you just need to
finish working on a task. If that's the case, you can always do
`renv::deactivate()` to stop using `{renv}` and `renv::activate()` to
reactivate it.

**Let's commit the changes made to the Git history**.

::: callout-info
**Before continuing to the next exercise, please read this**.

It's surprising how many issues can come up, from a reproducibility
perspective, when it comes to managing package dependencies. You think
something works well on your computer, but when you create a "virtual
environment" like you do when using `{renv}`, you realize it might not
work as well on other computers.

When this happens, there are several functions you can use to help debug
the situation.

`renv::diagnostics()`

:   List a *lot* of diagnostic information to look over. Sometimes its
    too much, but can help figure out what's going on.

`renv::clean()`

:   Installing packages can sometimes lead to issues in the files of the
    installed packages themselves or even left over temporary files.
    This function tries to clean up these issues for you. It can also
    clean up any unused packages

`renv::repair()`

:   Because of the way `{renv}` works, the connection to where an
    installed package is actually found can get broken. So this function
    tries to fix that and reinstall these broken packages.

`renv::rebuild()`

:   The last resort, use this to reinstall everything from scratch.
:::

## Exercise: Browse the newly created renv folders and files

> Time: \~10 minutes.

After running adding `{renv}` to the project, take a look through the
newly created `renv/` folder and see what was added. Where are the
packages now installed?

```{r ex-show-created-files}
#| echo: false
#| output: asis
fs::dir_tree(path = "renv", all = TRUE, recurse = 1)
```

To better understand how `{renv}` creates this self-contained project,
run this line of code:

```{r ex-lib-path-renv-active}
#| eval: false
.libPaths()
```

Notice where the file paths are. Then, run this code in the Console:

```{r ex-renv-deactivate}
#| eval: false
renv::deactivate()
```

Open up the Git interface and see what was modified in the `.Rprofile`
file. What was changed? Now switch back to the Console and run these
lines of code:

```{r ex-lib-path-renv-reactive}
#| eval: false
.libPaths()
renv::activate()
```

Notice how the file path location of the R library is different when
`{renv}` is active or not?

## Two types of dependencies

When you work on a research project that involves data analysis, you
make use of two types of packages:

1.  Packages you need to directly complete the analysis and generate the
    results. These types of packages...
2.  Packages that assist you in doing your work.

A good way to determine if a package is a *build dependency* for your
project is by seeing if you write and use functions from the package
within an R script that does something to the data or analysis. If you
*only* ever use functions from the package in the Console, than it is
likely a *workflow dependency*.

-   required vs helper packages (imports vs suggests)

    -   e.g. tidyverse in Depends?

-   Install only build dependencies if you track with DESCRIPTION:

```{r}
renv::install()
```

usethis::use_usethis()

## Exercise:

> Time: \~10 minutes

Discuss with your neighbours the following questions. At the end we will
write the code together.

1.  Since the project uses `{renv}`, would you categorize the package as
    a "workflow" dependency or a "build" dependency? Why? Depending your
    answer, would you do:
    1.  `use_package("renv", "Imports")`
    2.  `use_package("renv", "Suggests")`
2.  What about the `{usethis}` package? Which type of

## Programmatically follow a style guide

```{r}
#| eval: false
styler::style_dir()
```

Ctrl-Shift-P

-   caching `cache_activate()`

Change option in tools.

```{r}
options(
  styler.addins_style_transformer = "styler::tidyverse_style(indent_by = 4)"
)
```

## Exercise: Copy and paste code that is wrong.

1.  In your `doc/lesson.Rmd` file, create a new code chunk
    (`Ctrl-Shift-I` or `Ctrl-Shift-P` followed by typing "chunk") at the
    end of the file. Copy and paste the below code:

    ``` r
    lipidomics%>%select()
    ```

2.  In the bottom of your `R/functions.R` file, copy and paste the below
    code:

    ``` r
    ```

3.  Run `lintr::lint_dir()` in the Console. What happens? Don't do
    anything just yet, simply see what things were identified as
    potential issues.

4.  Normally you would want to run `styler::style_dir()` *after* you've
    committed everything to Git (just in case)

## Automatic linting checks

If you are collaborating on a project with collaborators who are not as
experienced or who only occasionally contribute, you might want to have
automatic linting checks (or styling) that are independent of you having
to run them yourself. If your project is on GitHub, there is a really
powerful service called [GitHub
Actions](https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions)

Can add GitHub Actions with lintr?

## Exercise: Connect your project to GitHub

> Time: \~20 minutes.

-   Read through Connecting to GitHub appendix.

## Adding lintr to the repository

use_github_action("lint-project")

## Styling Markdown files

For multi-person collaborative projects, having some type of code
styling and checker can really help with standardizing how the code
looks like, which ultimately will make it easier to read each others
code contributions.

But what about for Markdown files? While there isn't a package or
function (yet) that styles the Markdown files, RStudio does have an
option in their Tools to format Markdown into a "canonical form". The
reason for this option is because they added a "visual editor mode" to
writing R Markdown files (which is great if you are more comfortable
with apps like Word). Let's test out this option. First, let's make sure
everything has been committed to the Git history.

::: callout-warning
Use this option *only if* you have your project under Git version
control, since it will directly modify and overwrite the contents of the
entire file.
:::

There are two ways of doing this:

1.  Going into
    [`Tools -> Project Options -> R Markdown`](https://rstudio.github.io/visual-markdown-editing/options.html#project-options)
    and changing the options "Automatic text wrapping" to "column" (with
    the default 72 width value) and "Write canonical visual mode
    markdown" to "true".
2.  Or setting [YAML
    options](/https://rstudio.github.io/visual-markdown-editing/markdown.html#writer-options)
    in either the project-level `_quarto.yml` file (we will cover this
    in @sec-build-website) or at the file-level in the YAML header.

For right now, we will do the file-level YAML settings. Open the
`doc/lesson.Rmd` file and go to the top of the file. Right below the
last `---`, create a new line above it and paste this code in:

``` yaml
editor_options:
  markdown:
    wrap: 72
    canonical: true
```

Now, when you save your file, RStudio should automatically reformat the
Markdown into a standardized format. If you want to switch to using the
Visual Mode, use `Ctrl-Shift-F4` or the "Visual" button at the top of
the Source Pane beside the bolding and italicizing buttons.

The instructors won't be using the Visual Mode during the course,
however you are welcome to. We will be using the "canonical" markdown
mode though.

## Summary

