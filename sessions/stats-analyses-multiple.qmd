---
execute: 
  freeze: auto
---

# Efficiently running many analyses at once {#sec-stats-analyses-multiple}

{{< include ../includes/_wip.qmd >}}

```{r setup}
#| include: false
source(here::here("R/functions.R"))
extract_functions_from_qmd()
source(here::here("R/project-functions.R"))
library(tidyverse)
library(tidymodels)
load(here::here("data/lipidomics.rda"))
lipidomics_wide <- lipidomics %>%
  mutate(metabolite = snakecase::to_snake_case(metabolite)) %>%
  pivot_wider(
    names_from = metabolite, values_from = value, values_fn = mean,
    names_prefix = "metabolite_"
  )
metabolites_with_bootstrap_results <- read_csv(here::here("data/model-variation.csv"))
```

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Before beginning, get them to recall what they remember of the previous
session, either with something like Mentimeter or verbally. Preferably
something like Mentimeter because it allows everyone to participate, not
just the ones who are more comfortable being vocal to the whole group.

Depending on what they write, might need to briefly go over the previous
session.
:::

Rarely do we run only one single statistical model to answer one single
question, especially in our data-overflowing environments. An initial
instinct when faced with this task might be to copy-and-paste, then
slightly modify the code each time. Or, if you have heard of loops or
used them in other programming languages, you might think to create a
loop. Thankfully R uses something more powerful and expressive than
either of those approaches, and that is functional programming. Using
functional programming concepts, we can use little code to express
complex actions and run large numbers of statistical analyses.

Connected to the concept of functional programming, is the idea of
resampling a dataset multiple times and running the statistical analysis
on each resampled set to calculate a more accurate measure of
uncertainty. We often use generic calculations of uncertainty like the
standard error or the confidence interval. Those are useful measures
especially with very large datasets, however, they have limitations of
their own. By making use of resampling, we can identify how uncertain or
unreliable a statistical result might be for our specific dataset. This
session will be about using functional programming in the context of
statistical analysis and learning about other methods of determining
uncertainty.

## Learning objectives

The overall objective for this session is to:

1.  Describe the basic framework underlying most statistical analyses
    and use R to generate statistical results using this framework.

More specific objectives are to:

1.  Recall principles of functional programming and apply them to
    running statistical analyses by using the `{purrr}` package.
2.  Describe what a resampling technique is, the types available, and
    why it can help estimate the variability of model results. Apply
    functions from `{rsample}` and `{tune}` to use these techniques.
3.  Continue applying the concepts and functions used from the previous
    sessions.

Specific "anti"-objectives:

-   Same as the "anti"-objectives of @sec-stats-analysis-basic. NOTE: I
    don't this is showing right on the website?

## Exercise: How would we use functional programming to run multiple models?

> Time: \~20 minutes.

Functional programming underlies many core features of running
statistical methods on data. This exercise is meant for you to review
this concept and try to think of it in the context of statistical
modeling.

-   For 10 minutes, go to the sections on [Function
    Programming](https://r-cubed-intermediate.rostools.org/dry-functionals.html#functional-programming)
    in the Intermediate R course as well as the
    [split-apply-combine](https://r-cubed-intermediate.rostools.org/dry-functionals.html#split-apply-combine-technique-and-functionals)
    and review the concepts.

-   For 8 minutes, discuss with your neighbour how we can use functional
    programming to apply the statistical model to each metabolite. Try
    to think how the code would look. You don't need to write real R
    code, but if writing pseudocode helps, go right ahead! Also, don't
    look ahead :wink:

-   For the remaining time, we will discuss our thoughts in the whole
    group.

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

After they've finished, either write pseudocode in RStudio or draw this
out on a whiteboard if it is available. There will probably be several
different approaches, many of which could also be implemented just fine.
Ultimately we will replace `create_recipe_spec(metabolite_...)` with
`create_recipe_spec(starts_with("metabolite_"))`.
:::

## Apply logistic regression to each metabolite

You may have thought of many different ways to run the model on each
metabolite based on the `lipidomics_wide` dataset. However, these types
of "split-apply-combine" tasks are (usually) best done using data in the
long form. So we'll start with the original `lipidomics` dataset. Create
a header and code chunk at the end of the `doc/lesson.Rmd` file:

    ## Running multiple models

    ```{{r}}

    ```

The first thing we want to do is convert the metabolite names into snake
case:

```{r chain-col-to-snakecase}
lipidomics %>%
  column_values_to_snakecase(metabolite)
```

The next step is to split the data up. We could use `group_by()`, but in
order to make the most use of `{purrr}` functions like `map()`, we will
use `group_split()` to convert the data frame into a set of
lists[^stats-analyses-multiple-1]. Let's first add `{purrr}` as a
dependency:

[^stats-analyses-multiple-1]: There is probably a more computationally
    efficient way of coding this instead of making a list, but as the
    saying goes ["premature optimization is the root of all
    evil"](https://stackify.com/premature-optimization-evil/). For our
    purposes, this is a very good approach, but for very large datasets
    and hundreds of potential models to run, this method would need to
    be optimized some more.

```{r purrr-to-deps}
#| purl: true
#| eval: false
use_package("purrr")
```

Then we run `group_split()` on the `metabolite` column, which will
output a lot of data frames as a list.

```{r chain-split-by-metabolite}
lipidomics %>%
  column_values_to_snakecase(metabolite) %>%
  group_split(metabolite)
```

Remember that logistic regression models need each row to be a single
person, so we'll use the functional `map()` to apply our custom function
`metabolites_to_wider()` on each of the split list items:

```{r chain-map-to-wider}
lipidomics %>%
  column_values_to_snakecase(metabolite) %>%
  group_split(metabolite) %>%
  map(metabolites_to_wider)
```

Alright, we now a list of data frames where each data frame has only one
of the metabolites. These bits of code represent the conceptual action
of "splitting the data into a list by metabolites". Since we're
following a function-oriented workflow, let's create a function for
this. Convert it into a function, add the `r run_roxygen_comments`, run
`r run_styler_text`, move into the `R/functions.R` file, and then
`source()` the file.

```{r new-function-split-by-metabolite}
#' Convert the long form dataset into a list of wide form data frames.
#'
#' @param data The lipidomics dataset.
#'
#' @return A list of data frames.
#'
split_by_metabolite <- function(data) {
  data %>%
    column_values_to_snakecase(metabolite) %>%
    dplyr::group_split(metabolite) %>%
    purrr::map(metabolites_to_wider)
}
```

In the `doc/lesson.Rmd`, use the new function in the code:

```{r split-by-metabolite}
lipidomics %>%
  split_by_metabolite()
```

Like we did with the `metabolite_to_wider()`, we need to pipe the output
into another `map()` function that has a custom function that runs the
models. We don't have this function yet, so we need to create it. Let's
convert the modeling code we used in the exercise above into a function,
replacing `lipidomics` with `data` and using
`starts_with("metabolite_")` within the `create_recipe_spec()`. Add the
`r run_roxygen_comments`, run `r run_styler_text`, move into the
`R/functions.R` file, and then `source()` the file.

```{r new-function-generate-model-results}
#' Generate the results of a model
#'
#' @param data The lipidomics dataset.
#'
#' @return A data frame.
#'
generate_model_results <- function(data) {
  create_model_workflow(
    parsnip::logistic_reg() %>%
      parsnip::set_engine("glm"),
    data %>%
      create_recipe_spec(tidyselect::starts_with("metabolite_"))
  ) %>%
    parsnip::fit(data) %>%
    tidy_model_output()
}
```

Then we add it to the end of the pipe, but using `map_dfr()` to convert
to a data frame:

```{r chain-generate-model-results}
lipidomics %>%
  split_by_metabolite() %>%
  map_dfr(generate_model_results)
```

Since we are only interested in the model results for the metabolites,
let's keep only the `term` rows that are metabolites using `filter()`
and `str_detect()`.

```{r chain-filter-terms}
model_estimates <- lipidomics %>%
  split_by_metabolite() %>%
  map_dfr(generate_model_results) %>%
  filter(str_detect(term, "metabolite_"))
model_estimates
```

Wow! We're basically at our first `{targets}` output! Before continuing,
there is one aesthetic thing we can add: The original variable names,
rather than the snake case version. Since the original variable still
exists in our `lipidomics` dataset, we can join it to the
`model_estimates` object with `right_join()`, along with a few other
minor changes. First, we'll `seelct()` only the `metabolite` and then
create a duplicate column of `metabolite` called `term` (to match the
`model_estimates`) using `mutate()`.

```{r duplicate-original-vars}
lipidomics %>%
  select(metabolite) %>%
  mutate(term = metabolite)
```

Right after that we will use our custom `column_values_to_snakecase()`
function on the `term` column.

```{r dup-column-to-snakecase}
lipidomics %>%
  select(metabolite) %>%
  mutate(term = metabolite) %>%
  column_values_to_snakecase(term)
```

We can see that we are missing the `metabolite_` text before each snake
case'd name, so we can add that with `mutate()` and `str_c()`:

```{r dup-column-append-metabolite}
lipidomics %>%
  select(metabolite) %>%
  mutate(term = metabolite) %>%
  column_values_to_snakecase(term) %>%
  mutate(term = str_c("metabolite_", term))
```

There are 504 rows, but we only need the unique values of `term` and
`metabolite`, which we can get with `distinct()`.

```{r dup-column-distinct}
lipidomics %>%
  mutate(term = metabolite) %>%
  column_values_to_snakecase(term) %>%
  mutate(term = str_c("metabolite_", term)) %>%
  distinct(term, metabolite)
```

The last step is to `right_join()` with the `model_estimates`:

```{r dup-column-full-join}
lipidomics %>%
  mutate(term = metabolite) %>%
  column_values_to_snakecase(term) %>%
  mutate(term = str_c("metabolite_", term)) %>%
  distinct(term, metabolite) %>%
  right_join(model_estimates, by = "term")
```

Awesome :smile: Now can you guess what we are going to do next? That's
right, making a function of both the model creation code and this code
to add the original variable names. Then we can add our first
`{targets}` output!

## Exercise: Creating functions for model results and adding as a target in the pipeline

> Time: \~25 minutes.

Convert the code that calculates the model estimates as well as the code
that adds the original metabolite names into functions. Start with the
code for the metabolite names, using the scaffold below as a starting
point.

1.  Name the new function `add_original_metabolite_names`.
2.  Within the `function()`, add two arguments, where the first is
    called `model_results` and the second is called `data`.
3.  Paste the code we created into the function, replacing `lipidomics`
    with `data` and `model_estimates` with `model_results`.
4.  Add `dplyr::` and `stringr::` before their respective functions.
5.  Add the `r run_roxygen_comments`.
6.  Run `r run_styler_text` to the file to fix up the code.
7.  Cut and paste the function over into the `R/functions.R` file.
8.  Commit the changes you've made so far.

``` r
___ <- function(___, ___) {
  ___ %>%
}
```

```{r solution-new-function-add-original-metabolite-names}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
#' Add the original metabolite names (not as snakecase) to the model results.
#'
#' @param model_results The data frame with the model results.
#' @param data The original lipidomics dataset.
#'
#' @return A data frame.
#'
add_original_metabolite_names <- function(model_results, data) {
  data %>%
    dplyr::mutate(term = metabolite) %>%
    column_values_to_snakecase(term) %>%
    dplyr::mutate(term = stringr::str_c("metabolite_", term)) %>%
    dplyr::distinct(term, metabolite) %>%
    dplyr::right_join(model_results, by = "term")
}
```

Do the same thing with the code that creates the model results, using
the scaffold below as a starting point. The only difference here is that
we would like to save the model results to a CSV file in the `data/`
folder so we can more easily share the results.

``` r
calculate_estimates <- function(data, csv_path = "data/model-estimates.R") {
  model_estimates <- ___ %>%
    # All the other code to create the results
    ___ %>% 
    add_original_metabolite_names(data) 
  readr::write_csv(model_estimates, here::here(csv_path))
  output_switch_for_targets(model_estimates, csv_path)
}
```

```{r solution-new-function-calculate-estimates}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
#' Calculate the estimates for the model for each metabolite.
#'
#' @param data The lipidomics dataset.
#'
#' @return A data frame.
#'
calculate_estimates <- function(data, csv_path = "data/model-estimates.csv") {
  model_estimates <- data %>%
    column_values_to_snakecase(metabolite) %>%
    dplyr::group_split(metabolite) %>%
    purrr::map(metabolites_to_wider) %>%
    purrr::map_dfr(generate_model_results) %>%
    dplyr::filter(stringr::str_detect(term, "metabolite_")) %>%
    add_original_metabolite_names(data)
  readr::write_csv(model_estimates, here::here(csv_path))
  output_switch_for_targets(model_estimates, csv_path)
}
```

Lastly, add the model results output to end of the `_targets.R` file,
using the below scaffold as a guide.

1.  Use `df_model_estimates` for the `name`.
2.  Use the `calculate_estimates()` function in `command`, with
    `lipidomics` and `"data/model-estimates.csv"` as the arguments.
3.  Run `r run_styler_text` and than run `r run_tar_vis_text` to see if
    the new target gets detected. If it does, than run
    `r run_tar_make_text`.
4.  Commit the changes to the Git history.

``` r
list(
  ...,
  list(
    name = ___,
    command = ___(___, ___),
    format = "file"
  )
)
```

```{r purl-only-model-estimates-to-targets}
#| eval: false
#| echo: false
#| purl: true
update_target_calc_est <- '
  ),
  list(
    name = df_model_estimates,
    command = calculate_estimates(lipidomics, "data/model-estimates.csv"),
    format = "file"
  )
)
'
# print_lines("_targets.R")
revise_by_line_num(
  path = "_targets.R",
  insert_text = update_target_calc_est,
  # TODO: Modify these numbers.
  remove_original_lines = -30,
  insert_at_line = 31
)
targets::tar_visnetwork()
targets::tar_make()
git_ci("_targets.R", "Update targets with model results")
```

## Visualizing the model estimates

We've got one target done for the modeling stage, three more to go!
There are multiple ways of visualizing the results from models. A common
approach is to use a "dot-and-whisker" plot like you might see in a
meta-analysis. Often the "whisker" part is the measure of uncertainty
like the confidence interval, and the "dot" is the estimate. For the
confidence interval, we haven't calculated them at this point because
the typical approach doesn't exactly work for our data (tested before
the course). The next section will be covering another way of
determining uncertainty. For this plot though, we will use the standard
error of the estimate.

Inside the `doc/report.Rmd`, let's create a new header and code chunk
inside the `## Results` section. We'll want to use
`targets::tar_read(df_model_estimates)` so that `{targets}` is aware
that the R Markdown file is dependent on this target. This
`targets::tar_read()` will output a path to the CSV file, so we will
need to use `read_csv()` to load it in.

    ### Figure of model estimates

    ```{{r}}
    model_estimates <- targets::tar_read(df_model_estimates) %>% 
      read_csv()
    ```

<!-- TODO: Add this to purl for the report.Rmd? -->

```{r exec-only-model-estimates}
#| include: false
model_estimates <- here::here("data/model-estimates.csv") %>%
  readr::read_csv(show_col_types = FALSE)
```

Then we'll start using `{ggplot2}` to visualize the results. For
dot-whisker plots, the "geom" we would use is called
`geom_pointrange()`. It requires four values:

-   `x`: This will be the "dot", should we will use the `estimate`
    column.
-   `y`: This is the categorical variable that the "dot" is associated
    with, in this case, it is the `metabolite` column.
-   `xmin`: This is the lower end of the "whisker". Since the
    `std.error` is a value representing uncertainty of the estimate on
    either side of it (`+` or `-`), we will need to substract
    `std.error` from the `estimate`.
-   `xmax`: This is the upper end of the "whisker". Like `xmin` above,
    but adding `std.error` instead.

```{r plot-estimates-pointrange-only}
plot_estimates <- model_estimates %>% 
  ggplot(aes(
    x = estimate, 
    y = metabolite,
    xmin = estimate - std.error,
    xmax = estimate + std.error
  )) +
  geom_pointrange()
plot_estimates
```

Woah, there is definitely something wrong here. The values of the
estimate should realistically be somewhere between 0 (can't have a
negative odds) and 2 (in biology and health research, odds ratios are
rarely above 2), definitely unlikely to be more than 5. We will
eventually need to troubleshoot this issue, but for now, let's restrict
the x axis to be between 0 and 5.

```{r plot-estimates-coord-fixed}
plot_estimates +
  coord_fixed(xlim = c(0, 5))
```

There are so many things we could start investigating based on these
results in order to fix them up. But for now, this will do.

## Exercise: Add plot function as a target in the pipeline

> Time: \~15 minutes.

Hopefully you've gotten comfortable with the function-oriented workflow,
because we'll need to convert this plot code into a function and add it
as a target in the pipeline. Use the scaffold below as a guide.

1.  Replace `model_estimates` with `results`.
2.  Use the `output_switch_for_targets()` function we created to output
    either the `plot_results` or the `image_path`.
3.  Move the function into the `R/functions.R` file, add
    `r run_roxygen_comments`, and run `r run_styler_text`.

``` r
plot_estimates <- function(results, image_path) {
  plot_results <- ___ %>% 
    # Plot code here:
    ___
  ggplot2::ggsave(
   plot = plot_results,
   filename = here::here(image_path)
  )
  output_switch_for_targets(___, ___)
}
```

```{r solution-new-function-plot-estimates}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
#' Plot the estimates and standard errors of the model results.
#'
#' @param results The model estimate results.
#' @param image_path Path to where image will be saved.
#'
#' @return A ggplot2 figure.
#'
plot_estimates <- function(results, image_path) {
  plot_results <- results %>%
    ggplot2::ggplot(ggplot2::aes(
      x = estimate, y = metabolite,
      xmin = estimate - std.error,
      xmax = estimate + std.error
    )) +
    ggplot2::geom_pointrange() +
    ggplot2::coord_fixed(xlim = c(0, 5))

  ggplot2::ggsave(
    plot = plot_results,
    filename = here::here(image_path)
  )
  output_switch_for_targets(plot_results, image_path)
}
```

Then, after doing that, add the new function as a target in the
pipeline, name the new `name` as `fig_model_estimates`.

``` r
list(
  ...,
  tar_target(
    name = ___,
    command = plot_estimates(___, ___),
    format = "file"
  )
)
```

And replace all the plot code in the `doc/report.Rmd` file with the
`targets::tar_read()` inside the `knitr::include_graphics()`:

    ```{{r}}
    knitr::include_graphics(targets::tar_read(fig_model_estimates))
    ```

Run `r run_tar_make_text` to update the pipeline. Then commit the
changes to the Git history.

```{r purl-only-tar-make-fig-estimates}
#| eval: false
#| echo: false
#| purl: true
update_target_plot_est <- '),
tar_target(
  name = fig_model_estimates,
  command = plot_estimates(df_model_estimates, "images/fig-model-estimates"),
  format = "file"
)
)
'
# print_lines("_targets.R")
styler::style_file("_targets.R")
revise_by_line_num(
  path = "_targets.R",
  insert_text = update_target_calc_est,
  # TODO: Modify these numbers.
  remove_original_lines = -30,
  insert_at_line = 31
)

# TODO: Add R Markdown to be purled too.
targets::tar_visnetwork()
targets::tar_make()
git_ci("_targets", "Add plot estimates target")
```

## Determine variability in model estimates with resampling

Depending on the type of research questions, there are several ways to
assess variability (or uncertainty) in the model results. We could use
the calculated standard error of the estimate or calculate the
confidence interval from the standard error (using
`tidy(conf.int = TRUE)`). The disadvantage of this approach is that it
isn't very accurate for the data. Plus, when we have such small sample
sizes, some issues can limit the use of these typical measures of
uncertainty. And we've already noticed that there is something strange
with the estimates for some of the metabolites.

So instead, we can use something that is a bit more targetted to the
data called "resampling". There are many resampling techniques, and they
all have slightly different uses. The one we will use is called the
["bootstrap"](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))[^stats-analyses-multiple-2].
What bootstrapping does is take the data and randomly resamples it as
many times as there are rows. This means you can potentially resample
*the same data (in our case, person) more than once* (called "with
replacement"). So by pure chance, you could theoretically have a
"resampled set" from `lipidomics` where all 36 rows are only duplicate
data on one person!

[^stats-analyses-multiple-2]: Another common technique is called
    ["v-fold
    cross-validation"](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation),
    which is provides a way of assessing how well the model as a whole
    performs at fitting the data, rather than where bootstrap determines
    how varied the estimate can be.

<!-- TODO: Make a diagram of this at some point. -->

What's the advantage of this? It is a way of directly calculating the
standard error from the data itself (rather than from a formula), so it
gives a more accurate view of how uncertain the model estimate is for
our data. Usually, creating between 50 to 100 "resampled sets" is
sufficient to calculate a value for the variation. Because running
models with bootstrapped sets can take a long time to process, we will
only resample 10 times, or less if your computer is slow.

We're using the `{rsamples}` package to handle "resampling". So let's
add it to our dependency list:

```{r rsamples-to-deps}
#| purl: true
#| eval: false
use_package("rsamples")
```

We will eventually run bootstraps on all the metabolites, so we will
need to use our `split_by_metabolite()` function first. For now, we will
only use the first item in that list (accessed with `[[1]]`) to show
that the code works without running on all the metabolites every time.
Create another code chunk at the bottom of `doc/lesson.Rmd` to add this
code:

```{r split-metabolite-for-bootstrap}
lipidomics_list <- lipidomics %>%
  split_by_metabolite()
```

::: callout-info
## Reading task: \~10 minutes

> *You don't need to run the code in this reading section*.

The `bootstraps()` function is how we create resampled sets. Since this
is done randomly, we should use `set.seed()` in order for the analysis
to be reproducible. Nothing is truly random in computers, and instead is
actually "pseudorandom". In order for our analysis to be reproducible,
we use `set.seed()` to force a specific "pseudorandom" value.

```{r show-bootstrap-first-item}
set.seed(1324)
bootstraps(lipidomics_list[[1]], times = 10)
```

This output is called a "nested tibble". A nested tibble is a
tibble/data frame where one or more of the columns are actually a list
object. In our case, each bootstrapped set (marked by the `id`) has
instructions on how the resampled data will look like. We can see what
it looks like by accessing the `splits` column and looking at the first
item with `[[1]]`:

```{r show-split-contents}
bootstraps(lipidomics_list[[1]], times = 10)$splits[[1]]
```

The contents of this resampled set are split into "analysis" sets and
"assessment" sets. You don't need to worry about what these mean or how
to use them, since a function we will later use handles it for us. But
to give you an idea of what bootstrapping is doing here, we can access
one of the sets with either the `analysis()` or `assessment()`
functions. We'll `arrange()` by `code` to show how we can have duplicate
persons when resampling:

```{r show-split-contents-analysis}
bootstraps(lipidomics_list[[1]], times = 10)$splits[[1]] %>%
  analysis() %>%
  arrange(code)
```

See how some `code` IDs are the same? Those are the same person that has
been selected randomly into this resampled set.
:::

Like we did with the previous modeling, we need to create a workflow
object. We'll use the first metabolite (`lipidomics_list[[1]]`) for now,
but will revise the code to eventually run the bootstrapping on all
metabolites.

```{r create-workflow-for-bootstrap}
workflow_for_bootstrap <- create_model_workflow(
  logistic_reg() %>%
    set_engine("glm"),
  lipidomics_list[[1]] %>%
    create_recipe_spec(starts_with("metabolite_"))
)
```

Previously, we used `fit()` on the workflow and on the data. Instead, we
will use `fit_resamples()` to run the model on the bootstrapped data.
Instead of the `data` argument in `fit()`, it is the `resamples`
argument where we provide the `bootstraps()` sets. We could run the code
with only the workflow object and the resampled data, but there's an
extra argument in `fit_resamples()` that `control`'s some actions taken
during the fitting by using the `control_resamples()` function. For
instance, we can save the predictions with `save_pred = TRUE` and we can
process the output with our `tidy_model_output()` function in the
`extract` argument. So let's do that. First, both `fit_resamples()` and
`control_resamples()` come from the `{tune}` package, so let's add it to
the dependencies first.

```{r tune-to-deps}
#| purl: true
#| eval: false
use_package("tune")
```

Now, we can write the code for `fit_resamples()` on the `bootstraps()`
of the first item in the `lipidomics_list` and setting the `control`
options with `control_resamples()`.

```{r fit-on-resampled-sets}
bootstrapped_results <- fit_resamples(
  workflow_for_bootstrap,
  resamples = bootstraps(lipidomics_list[[1]], times = 10),
  control = control_resamples(
    extract = tidy_model_output,
    save_pred = TRUE
  )
)
bootstrapped_results
```

You'll see that it gives another nested tibble, but with more columns
included. Before we start selecting the results that we want, let's
convert the code above into a function, using the function-oriented
workflow we've used throughout the course.

```{r new-function-generate-model-variation}
#' Generate the model variation results using bootstrap on a single metabolite.
#'
#' @param data The lipidomics data.
#'
#' @return A nested tibble.
#'
generate_model_variation <- function(data) {
  create_model_workflow(
    parsnip::logistic_reg() %>%
      parsnip::set_engine("glm"),
    data %>%
      create_recipe_spec(tidyselect::starts_with("metabolite_"))
  ) %>%
    tune::fit_resamples(
      resamples = rsample::bootstraps(data, times = 10),
      control = tune::control_resamples(
        extract = tidy_model_output,
        save_pred = TRUE
      )
    )
}
```

Re-writing the code to use the function, it becomes:

```{r use-generate-variation-function}
bootstrapped_results <- lipidomics_list[[1]] %>%
  generate_model_variation()
bootstrapped_results
```

Let's explain this output a bit. The `fit_resamples()` function outputs
a nested tibble, where each row is a resampled set. The columns that
begin with `.` (`.metrics` or `.extracts`) are extracted details from
each model fit to the resampled set. We'll ignore all but the
`.extracts` column, since that is the column that we set to extract the
`tidy_model_output()`. Let's `select()` only the `id` and the
`.extracts` column and use `unnest()` to convert the nested tibble to a
regular tibble based on the column given.

```{r unnext-extracts}
bootstrapped_results %>%
  select(id, .extracts) %>%
  unnest(cols = .extracts)
```

Alright, this is actually another nested tibble (we can see based on the
new column `.extracts` where each row is called a `<tibble>`). So let's
again `unnest()` this new `.extracts` column.

```{r unnest-unnest-bootstrap}
bootstrapped_results %>%
  select(id, .extracts) %>%
  unnest(cols = .extracts) %>%
  unnest(cols = .extracts)
```

Now this is something we are familiar with looking at! It shows the
`term`, the `estimate`, as well as the bootstrap `id`. Like before, we
only want the metabolite `estimate`, so we can use `filter()` and
`str_detect()` like last time, as well as add the original variable
names with `add_original_metabolite_names()`.

```{r unnest-unnest-tidy-bootstrap-results}
bootstrapped_results %>%
  select(id, .extracts) %>%
  unnest(cols = .extracts) %>%
  unnest(cols = .extracts) %>%
  filter(str_detect(term, "metabolite_")) %>%
  add_original_metabolite_names(lipidomics)
```

Using the same workflow as before, let's convert this into a function:

```{r new-function-tidy-bootstrap-output}
#' Tidy up the bootstrap output.
#'
#' @param bootstrap_results The bootstrap object with model results.
#'
#' @return A data frame.
#'
tidy_bootstrap_output <- function(bootstrap_results) {
  bootstrap_results %>%
    dplyr::select(id, .extracts) %>%
    # Need to unnest twice since first `.extracts` is a nest of another two
    # columns of `.extracts` and `.config`.
    tidyr::unnest(cols = .extracts) %>%
    tidyr::unnest(cols = .extracts) %>%
    dplyr::filter(stringr::str_detect(term, "metabolite_")) %>%
    add_original_metabolite_names(lipidomics)
}
```

Then we can start from the beginning again, right from `lipidomics`, to
`split_by_metabolite()`, to `map()`'ing with
`generate_model_variation()`, and finally to `map_dfr()` with
`tidy_bootstrap_output()`. Keep in mind, this will take a while to run.

```{r chain-data-to-bootstrap-results}
#| eval: false
metabolites_with_bootstrap_results <- lipidomics %>%
  split_by_metabolite() %>%
  map(generate_model_variation) %>%
  map_dfr(tidy_bootstrap_output)
metabolites_with_bootstrap_results
```

```{r exec-only-show-bootstrap-results}
#| echo: false
metabolites_with_bootstrap_results
```

## Exercise: Convert to function and add as a target in the pipeline

> Time: \~15 minutes.

Continue the workflow we've applied throughout the course:

1.  Move the code into a function structure (use the scaffold below as a
    guide).
2.  Include two arguments in the `function()` called `data` and
    `results_path`.
3.  Replace `lipidomics` in the code with `data`.
4.  Add the `r run_roxygen_comments`.
5.  Cut and paste the function over into the `R/functions.R` file.
6.  Run `r run_styler_text` and `r run_lintr_text` (try to fix any
    issues).
7.  Commit the changes to the Git history.

Use this code as a guide for the function.

``` r
calculate_variation <- function(___, results_path = "data/model-variation.csv") {
  bootstrapped_results <- ___ %>% 
    # Code from above.
    ___
  readr::write_csv(bootstrapped_results, here::here(results_path))
  output_switch_for_targets(bootstrapped_results, results_path)
}
```

```{r solution-new-function-calculate-variation}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
#' Calculate the uncertainty in results.
#'
#' @param data The lipidomics data.
#' @param results_path Path to save a CSV of the results.
#'
#' @return A data frame (or file path)
#'
calculate_variation <- function(data, results_path = "data/model-variation.csv") {
  bootstrapped_results <- data %>%
    split_by_metabolite() %>%
    map(generate_model_variation) %>%
    map_dfr(tidy_bootstrap_output)
  readr::write_csv(bootstrapped_results, here::here(results_path))
  output_switch_for_targets(bootstrapped_results, results_path)
}
```

Next, add the function to `_targets.R`.

1.  Create another `tar_target()` item in the `list()` at the bottom of
    the file.
2.  Use `df_model_variation` as the `name` and `calculate_variation()`
    as the `command` with `lipidomics` and `"data/model-variation.csv"`
    as the two arguments.
3.  Set `"file"` as the `format`.
4.  Run `r run_tar_vis_text` to see what targets are outdated and then
    run `r run_tar_make_text`.
5.  Commit the changes to the Git history.

Use this code as a scaffold:

``` r
list(
  ...,
  tar_target(
    name = ___,
    command = ___,
    format = ___
  )
)
```

```{r solution-calculate-variation-to-pipeline}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
list(
  # ...,
  tar_target(
    name = df_model_variation,
    command = calculate_variation(lipidomics, "data/model-variation.csv"),
    format = "file"
  )
)
```

## Visualizing the variability of results

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Take your time explaining why we might use a figure like this, and what
you're trying to show. Since there isn't much code involved, there is
time to explain.
:::

Like we did with the estimates, let's visualize the results. Visualizing
the estimates was pretty easy, visualizing the variation is even easier.
We want to show the range of `estimate` values across all the
bootstrapped models, by `metabolite` variable. There's a neat geom in
`{ggplot2}` called `geom_dotplot()` that is similar to a histogram, but
instead shows individual data points instead of bars. And since we want
to show the variation by `metabolite`, we can use `facet_wrap()`. We
will use `scales = "free"` because the range of values for `estimate`
are different for each `metabolite`.

```{r plot-variation}
metabolites_with_bootstrap_results %>%
  ggplot(aes(x = estimate)) +
  geom_dotplot() +
  facet_wrap(vars(metabolite), scales = "free")
```

This nicely shows the ranges of values in the `estimate`, really
highlighting how uncertain the results are for answering our original
research questions. This figure could also be improved quite a bit from
a visual and aesthetic point of view, but at least from a content point
of view, it shows what we want. For now, we'll stick with this and
finish our last pipeline target before putting everything into the
`doc/report.Rmd` file.

Let's use our function workflow with this code:

1.  Create the code as a function, add a `data` argument, and replace
    the input data object name with `data`.
2.  Move the code into the `R/functions.R` file.
3.  Add the `r run_roxygen_comments` and fill it in.
4.  Run `r run_styler_text`.

```{r new-function-plot-variation}
#' Plot the uncertainty in the estimates of the models.
#'
#' @param model_results The model results with the variation.
#'
#' @return A ggplot2 image (or a file path).
#'
plot_variation <- function(model_results, image_path) {
  plot_output <- model_results %>%
    ggplot2::ggplot(ggplot2::aes(x = estimate)) +
    ggplot2::geom_dotplot() +
    ggplot2::facet_wrap(ggplot2::vars(metabolite), scales = "free")
  ggplot2::ggsave(here::here(image_path), plot_output)
  output_switch_for_targets(plot_output, image_path)
}
```

Then we'll add it as a pipeline target to the `_targets.R` file.

``` r
list(
  ...,
  tar_target(
    name = fig_model_variation,
    command = plot_variation(df_model_variation, "images/fig-model-variation.png"),
    format = "file"
  )
)
```

Run `r run_tar_vis_text` and then run `r run_tar_make_text`. Once
everything has been built, commit everything to the Git history.

## Combine all the output into the R Markdown file

Now its' time to add the model results and plots to the `doc/report.Rmd`
file. Open it up and create another code chunk at the bottom of the
file. Like we did with the other outputs (like the figures), we'll use
`tar_read()` to reference the image path.

    ```{{r}}
    knitr::include_graphics(tar_read(fig_model_estimates))
    ```

    ```{{r}}
    knitr::include_graphics(tar_read(fig_model_variations))
    ```

Run `r run_tar_vis_text`, then `r run_tar_make_text`. We now have the
report rendered to an HTML file! If you open it up in a browser, we can
see the figures added to it. In the next session we will get more into
making the document output nicer looking and creating it as a website.

TODO: Check that the output is rendered to html.

## Summary

-   Use functional programming with `map()`, as part of the
    function-oriented workflow, to run multiple models efficiently and
    with minimal code.
-   Consistently create small functions that do a specific conceptual
    action and chain them together into larger conceptual actions, which
    can than more easily be incorporated into a `{targets}` pipeline.
    Small, multiple functions combined together are easier to manage
    than fewer, bigger ones.
-   Use dot-whisker plots like `geom_pointrange()` to visualize the
    estimates and their standard error.
-   Use resampling techniques like `bootstraps()`, combined with
    `fit_resamples()`, to calculate measures of variation specific to
    the data. Combine with functionals like `map()` to run large numbers
    of models, easily and with minimal code.
-   Visualize variation in data with alternatives to histograms like
    `geom_dotplot()`.

