# Running efficient statistical analyses {#sec-statistical-analyses}

{{< include ../includes/_wip.qmd >}}

```{r setup}
#| include: false
library(tidyverse)
library(tidymodels)
load(here::here("data/lipidomics.rda"))
```

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Before beginning, get them to recall what they remember of the previous
session, either with something like Mentimeter or verbally. Preferably
something like Mentimeter because it allows everyone to participate, not
just the ones who are more comfortable being vocal to the whole group.
:::

TODO: intro here

## Learning objectives

The overall objective for this session is to:

1.  Describe the basic framework underlying most statistical analyses
    and use R to generate statistical results using this framework.

More specific objectives are to:

1.  Describe the general "workflow" and steps involved in stating the
    research question, constructing a model to help answer the question,
    preparing the data to match the requirements of the model, fitting
    it to the data, and finally extracting the results from the fitted
    model.
2.  Categorize the model definition step as a distinct, theory-driven
    step, separate from the data, and use `{parsnip}` functions to help
    with defining your model.
3.  Identify various data transformation techniques and evaluate which
    are good options given the data. Use functions in the `{recipes}`
    package to apply these transformations to your data.
4.  Recall principles of functional programming and apply them to
    running statistical analyses by using the `{purrr}` package.
5.  Use the `{broom}` package to extract the model results to later
    present them in tabular (with `knitr::kable()`) or graphical format
    (with `{ggplot2}`).
6.  Describe what a resampling technique is, the types available, and
    why it can help estimate the variability of model results. Apply
    functions from `{rsample}` to use these techniques.
7.  Continue applying the concepts and functions used from the previous
    sessions.

Specific "anti"-objectives:

-   Will **not** know how to choose and apply the appropriate
    statistical model or test, nor understand any statistical theory,
    nor interpret the statistical results correctly, nor determine the
    relevant data transformations for the statistical approach. What we
    show, we show *only as demonstration purposes only*, they could be
    entirely wrong in how to do them correctly if an expert were to
    review them.

## Exercise: What does a "model" mean?

> Time: \~8 minutes.

In science and especially statistics, we talk a lot about "models". But
what does model actually mean? What different types of definitions can
you think of? Is there a different understanding of model in statistics
compared to other areas?

1.  Take 1 minute to think about your understanding of a model.
2.  Then, over the next 4 minutes, discuss with your neighbour about the
    meaning of "model" and see if you can come to a shared
    understanding.
3.  Finally, over the next 3 minutes, we will share all together what a
    model is in the context of data analysis.

## Theory and "workflow" on statistical modeling

Almost all fields of research, and definitely more heavily-quantitative
and scientific fields like biomedicine and health, have math and
statistics at the core of taking data to draw inferences or general
observations about the world, at least the world that we measure.

Any time we collect data and need to interpret what it means, we need
statistics. And anytime we want to make inferences about the world from
the data, to generalize to the outside world, we need to use statistics
to determine the likelihood, or rather the uncertainty, in those
inferences. Statistics is meant to quantify uncertainty.

How do we quantify uncertainty? By first creating a "theoretical model"
that expresses mathematically our research question. For instance, we
have a theoretical model that outdoor plants grow (non-linearly) with
water and sunlight, but that more sunlight likely means less water (less
rain). While *any* research question could be translated into a
theoretical model, not all theoretical models can be *tested* against
the real world. And that's where the second part comes in: Our
theoretical model needs to be structured in a way that allows us to
measure the items ("parameters") in our model, so that we can build a
mathematical model from the data ("test it in the real world").

```{mermaid fig-model-plant-growth}
%%| label: fig-model-plant-growth
%%| fig-cap: Simple example of a theoretical model of plant growth.
%%| echo: false
%%| eval: true
%%{init:{'theme':'forest', 'flowchart':{'nodeSpacing': 20, 'rankSpacing':30}, 'themeVariables': { 'edgeLabelBackground': 'transparent'}}}%%
graph LR
    Sunlight --> Growth
    Water --> Growth
    Sunlight --- Water

linkStyle 0,1,2 stroke-width:1px;
```

Great research questions are designed in a way to fit a theoretical
model on measurable parameters, so we can ultimately quantify the
uncertainty in our observations (the data) and in the model. And the
basic simplified math of a statistical model looks mostly the same:

$$y = intercept + x + error $$

It's a bit more complicated than this, but this is enough to describe
for this course. Throughout the rest of the session, we use specific
terms to describe each item in this formula. "Outcome" (also called
"dependent variable") refers to the $y$, "predictor" (or "independent
variable") refers to the $x$. The error and intercept are calculated for
us when we fit the model to the data. The intercept is when x is equal
to zero (the "y-intercept" on a plot). The error is difference better
what the model estimates and what the real value is. It plays a role in
quantifying the model's uncertainty.

Considering the mathematical nature of statistical models, there is also
a logic and "workflow" to making these models as well!

1.  Write a research question, designed in a way that might look like
    the diagram above. Usually this step may need to be done back and
    forth, revising the question after trying to construct the
    theoretical model, that describes the measurable (and unmeasurable)
    parameters in the model, and vice versa.
2.  Based on the model and the type of measured parameters used
    (continuous vs binary), select the best mathematical model "type".
    Nearly all models in statistics start from the base of a linear
    regression (e.g. ANOVA is a special form of regression, t-test is a
    simpler version of ANOVA), so the model "type" will probably be a
    form of regression.
3.  Measure your parameters (in the plant growth example, that might be
    the amount of water given in liters per day, amount of plant growth
    in weight, and amount of sunlight in hrs per day). Usually, this
    measured data might need to be processed in a special way to fit the
    specifics of the model, research question, and practices of the
    field.
4.  Fit the data to the theoretical model in order to estimate the
    values ("coefficients") of the model parameters as well as the
    uncertainty in those values.
5.  Extract the values and their uncertainty from the model and present
    them in relation to your research questions.

<!-- TODO: Image of workflow? -->

::: callout-caution
The entire workflow for building statistical models requires highly
specific domain knowledge on not only the statistics themselves, but
also how the data was collected, what the values mean, what type of
research questions to ask and how to ask them, how to interpret the
results from the models, and how to process the data to fit the question
and model.

For instance, in our `lipidomics` dataset, if we were to actually use
this data, we would need someone familiar with -omic technologies, how
the data are measured, what the values actually mean, how to prepare
them for the modeling, the specific modeling methods used for this
field, and how we would actually interpret the findings. We have
**none** of these things, so very likely we are doing things quite wrong
here. We're only doing these modeling to highlight how to use the R
packages.
:::

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

A few things to repeat and reinforce:

1.  The workflow of the image and that it all starts with the research
    question.
2.  The fact that almost all statistical methods are basically special
    forms of linear regression.
3.  That this model creation stage requires a variety of domain
    expertise, not just statistical expertise.
:::

Going back to our own `lipidomics` dataset, we need to do the first
step. And that is creating the question. While we don't have much data,
there are a surprising number of questions we could ask. But we will
keep it very simple, very basic, and very exploratory.

1.  What is the estimated relationship of each metabolite with T1D
    compared to control, adjusting for the influence of age and gender?
2.  What is the variability for the estimate in each relationship?

Next, because we are working within a "reproducible analysis" framework
specifically with the use of `{targets}`, let's convert these questions
in outputs to include as pipeline targets, along with a basic idea for
the final functions that will make up these targets and their inputs and
outputs. These targets will probably be quite different by end, but its
a good to start thinking about what the end should look like.

-   All results for estimated relationship (in case we want to use it
    for other output)
-   All results for variation in estimates of relationship (in case we
    want to use it for other output)
-   Plot of statistical estimate for each relationship
-   Plot of variation in estimates for each relationship

Potential function names might be:

-   `calculate_estimates()`
-   `calculate_variation()`
-   `plot_estimates()`
-   `plot_variation()`

```{mermaid fig-model-possible-targets}
%%| label: fig-model-possible-targets
%%| fig-cap: Potential inputs, outputs, and functions for the targets pipeline.
%%| echo: false
%%| eval: true
%%{init:{'theme':'forest', 'flowchart':{'nodeSpacing': 20, 'rankSpacing':30}, 'themeVariables': { 'edgeLabelBackground': 'transparent'}}}%%
graph TB
    lipidomics -- "calculate_estimates()" --> model_est[Model estimates]
    model_est -- "plot_estimates()" --> plot_est[Plot of estimates]
    lipidomics -- "calculate_variation()" --> model_var[Model variation]
    model_var -- "plot_variation()" --> plot_var[Plot of variation]
    plot_est & plot_var --> rmd[R Markdown]

linkStyle 0,1,2,3,4,5 stroke-width:1px;
```

## Defining the model

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Verbally walk through this section, describing the theoretical model
both graphically and mathematically. Go through why we use
`{tidymodels}` rather than other approaches.
:::

Now that we've talked about the workflow around making models and have
already written out some research questions, let's make a basic,
graphical theoretical model:

```{mermaid fig-model-research-question}
%%| label: fig-model-research-question
%%| fig-cap: Simple example of a theoretical model of plant growth.
%%| echo: false
%%| eval: true
%%{init:{'theme':'forest', 'flowchart':{'nodeSpacing': 20, 'rankSpacing':30}, 'themeVariables': { 'edgeLabelBackground': 'transparent'}}}%%
graph TB
    Metabolite --> T1D
    Age & Gender --> T1D & Metabolite

linkStyle 0,1,2,3,4 stroke-width:1px;
```

Or mathematically:

$$T1D = metabolite + age + gender$$

So, T1D status (or `class` in the `lipidomics` dataset) is our
**outcome** and the individual metabolite, age, and gender are our
**predictors**. Technically, age and gender would be "confounders" or
"covariates", since we include them only because we think they influence
the relationship between the metabolite and T1D.

Now that we have a theoretical model, we need to choose our model type.
Since T1D is binary (either you have it or you don't), the most likely
choice is logistic regression, which requires a binary outcome variable.
So we have the theoretical model and the type of model to use, how do we
express this as code in R? There are many ways of doing the same thing
in R. But some are a bit easier than others. One such approach, that is
quite generic and fits with the ideals of the `{tidyverse}`, is a
similar universe of packages called the `{tidymodels}`.

Why do we teach `{tidymodels}`? Because they are built by software
developers, employed by RStudio (who also employs the people who build
the `{tidyverse}`), and they have a strong reputation for writing good
documentation. Plus, the `{tidymodels}` set of packages also make
creating and using models quite generic, so by teaching you these sets
of tools, you can relatively easily change the model type, or how you
process the data, or other specifications without having to learn a
whole new package or set of tools.

The reason `{tidymodels}` can do that is because they designed it in a
way that makes a clear separation in the components of model building
workflow that was described above, through the use of specific packages
for each component.

| Package       | Description                                                                                       |
|---------------|---------------------------------------------------------------------------------------------------|
| `{parsnip}`   | Model definition, such as type (e.g. `linear_reg()`) and "engine" (e.g. `glm()`).                 |
| `{recipes}`   | Model-specific data transformations, such as removing missing values, or standardizing the data.  |
| `{workflows}` | Combining model definition, data, and transformations to calculate the estimates and uncertainty. |

: Core packages within `{tidymodels}`.

We'll start with the `{parsnip}` package first. Functions in this
package are used to set the details of the model you want to use.
Specifically,
[functions](https://parsnip.tidymodels.org/reference/index.html#models)
to indicate the model *"type"* (e.g. linear regression) and the
`set_engines()` function to determine the "engine" to run the type
(which R-based algorithm to use, like `glm()` compared to `lm()`). Check
out the
[Examples](https://parsnip.tidymodels.org/articles/Examples.html) page
for code you might use depending on the model you want. The most
commonly used model types would be `linear_reg()`, `logistic_reg()`, and
`multinom_reg()`.

We want to use logistic regression. So, open the `doc/lesson.Rmd` file
and in the `setup` code chunk add `library(tidymodels)`, so it looks
like:

    ```{{r setup}}
    library(tidyverse)
    library(tidymodels)
    load(here::here("data/lipidomics.rda"))
    ```

Since we will be using `{tidymodels}`, we need to install it, as well as
explicitly add the `{parsnip}`, `{recipes}`, and `{workflows}` packages
we will use. Like `{tidyverse}`, we need to set `{tidymodels}`
differently because it is a "meta-package". We might need to force
installing it with `install.packages("tidymodels")` so `{renv}`
recognizes it.

```{r}
#| purl: true
#| eval: false
use_package("tidymodels", "depends")
# install.packages("tidymodels")
use_package("parsnip")
use_package("recipes")
use_package("workflows")
```

Before continuing, let's **commit** the changes to the Git history.
Next, in the `doc/lesson.Rmd` file, on the bottom of the document create
a new header and code chunk:

    ## Building the model

    ```{{r}}

    ```

In the new code chunk, we will set up the model specs:

```{r logistic-reg-specs}
log_reg_specs <- logistic_reg() %>% 
  set_engine("glm")
log_reg_specs
```

Running this on it's own doesn't show much, as you can see. But we've
now set the model we want to use.

## Exercise: How would you define a linear regression with parsnip?

> Time: \~10 minutes.

Using [parsnip's "Examples"
vignette](https://parsnip.tidymodels.org/articles/Examples.html) as well
as the code we wrote for the logistic regression above as a template,
write `{parsnip}` code that would define a simple (an engine of`"lm"`)
linear regression model. Begin by making a new Markdown header and code
chunk at the bottom of the `doc/lesson.Rmd` file, like listed below:

    ## Exercises
    ### Linear regression model definition

    ```{{r}}

    ```

After writing the code, run `r run_styler_text`. We will eventually
delete these exercise text in the R Markdown file, but for now, commit
the changes to the Git history.

```{r solution-define-linear-reg-model}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
linear_reg_specs <- linear_reg() %>% 
  set_engine("lm")
```

## Data transformations specific to modeling

-   Some problems:

    -   we have three cholesterol values
    -   values all have different ranges, will be an issue for
        interpreting model estimates across metabolites
    -   long data format

```{r}
library(tidyverse)
load(here::here("data/lipidomics.rda"))
lipidomics %>%
  count(code, metabolite) %>%
  filter(n > 1)
```

```{r}
lipidomics_wide <- lipidomics %>%
  mutate(metabolite = snakecase::to_snake_case(metabolite)) %>%
  pivot_wider(names_from = metabolite, values_from = value, values_fn = mean)
```

-   recipes

-   convenient with `recipes::step_impute_*` functions

recipes::step_naomit()

## Exercise: Which transformations make the most sense?

> Time: \~15 minutes.

Look at the list of `step_*` functions below and use the `?` or F1
(while having the cursor on the function name) to access the help
documentation. Consider the metabolite data in the `lipidomics` dataset.
Which of these transformations might you use?

```{r list-step-transforms}
#| eval: false
recipes::step_log()
recipes::step_scale()
recipes::step_normalize()
recipes::step_center()
recipes::step_sqrt()
```

-   With your neighbour (or group), justify which `step_` transformation
    you might use for the numeric metabolite data.
-   In the last 2 minutes of the exercise, we will all share our
    thoughts.

::: callout-note
The `step_` function we use in the text of this website in later
sections may be different from what you decide on in your group and in
the class as a whole. There isn't strictly a "right" answer here, since
it would ultimately require domain expertise in both lipidomic
quantification and statistical analysis of -omic data. But we ultimate
need to show and use *something* in the text.
:::

## Creating a transformation "recipe"

## Fitting the model by combining the recipe, model definition, and data

```{r}
workflows::workflow()
```

## Exercise: Run model with a different metabolite

> Time: \~10 minutes.

Try running the same model workflow but run the model with
`lipid_ch_3_1` instead of `cholesterol`.

1.  In the `doc/lesson.Rmd` file, create a new `###` header and code
    chunk at the bottom of the R Markdown file (see the scaffold
    template below).
2.  Start with creating a new data frame (call it `df_lipid_ch_3_1`),
    `select()`ing `class`, `gender`, `age`, and `lipid_ch_3_1`.
3.  Copy and paste the previous recipe `recipe_specs` we created above
    and then replace all `cholesterol` with `lipid_ch_3_1`.
4.  Copy and paste the same `model_workflow` code we created above,
    re-using both the same `log_reg_specs` in the `add_model()` function
    and `recipe_specs` (the one you modified in the task above) in the
    `add_recipe()` function.
5.  Run `fit()` on the `model_workflow`, making sure to use the
    `df_lipid_ch_3_1` in the `data` argument.
6.  Run the `fitted_model` in the Console to get the output results.
    What is the coefficient for the `lipid_ch_3_1` compared to the
    `cholesterol` result?
7.  Use `r run_styler_text` on the R Markdown file. Then commit the
    changes to the Git history.

Use the scaffolding below as a guide. *Note*: The code has been
purposefully written poorly so you can use `{styler}` to fix it up.

    ### Model with a different metabolite
    ``` {{r}}
    ___ <- lipidomics_wide%>%select(___,___,___,___)

    recipe_specs<-recipe(class ~ ___ +age+gender, 
    data = ___) %>% 
      step_normalize(___)

    model_workflow <- workflow()%>% ___(___) %>% 
      ___(___)
      
    fitted_model <- fit(model_workflow,data=___)
      fitted_model
    ```

```{r solution-model-with-different-metabolite}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
df_lipid_ch_3_1 <- lipidomics_wide %>% 
  select(class, gender, age, lipid_ch_3_1)

recipe_specs <- recipe(class ~ lipid_ch_3_1 + age + gender, data = df_lipid_ch_3_1) %>% 
  step_normalize(lipid_ch_3_1)

model_workflow <- workflow() %>% 
  add_model(log_reg_specs) %>% 
  add_recipe(recipe_specs)
  
fitted_model <- fit(model_workflow, data = df_lipid_ch_3_1)
fitted_model
```

<!-- TODO: Do I need to purl this at this point? Or only later as a function? -->

## Extracting results from the fitted models

-   broom

    -   tidy
    -   augment?

## Exercise: How would we use functional programming to run multiple models?

> Time: \~20 minutes.

Functional programming underlies many core features of running
statistical methods on data. This exercise is meant for you to review
this concept and try to think of it in the context of statistcal
modeling.

-   For 10 minutes, go to the section on [Function
    Programming](https://r-cubed-intermediate.rostools.org/dry-functionals.html#functional-programming)
    in the Intermediate R course and review the concepts.

-   For 8 minutes, discuss with your neighbour how we can use functional
    programming to apply the model to each metabolite. Try to think how
    the code would look like to that that. You don't need to write real
    R code, but if writing pseudocode helps, go right ahead! Also, don't
    look ahead :wink:

-   For the remaining time, we will discuss as the whole group
    somethings people thought of.

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

After they've finished, either write pseudocode in RStudio or draw this
out on a whiteboard if it is available.
:::

## Apply logistic regression to each metabolite

```{r}
lipidomics %>% 
  filter(metabolite == "Lipid -CH2-") %>% 
  ggplot(aes(x = value, fill = class)) +
  geom_dotplot(binwidth = 10)
```

## Determine variability in model estimates with resampling

-   rsamples with plotting of each estimates

-   Use bootstrap, but mention vfold_cv

## Exercise: Running multiple models by metabolite *and* re-sampled bootstrapped set

## Visualizing the variability of results

-   Combine augment with rsamples and ggplot2 to plot different
    estimates

```{r}
#| eval: false
lipidomics %>%
  # Deal with multiple cholesterols?
  # group_by(code, gender, age, class, metabolite) %>%
  # # .groups = "drop" to remove group_by structure, so we don't need to use ungroup
  # summarise(value = mean(value), .groups = "drop") %>%
  mutate(metabolite = snakecase::to_snake_case(metabolite)) %>%
  group_split(metabolite) 
  # map(~pivot_wider(.x, names_from = metabolite, values_from = value, values_fn = mean))
  
```

## Exercise: Convert model building code into functions for targets

## Summary

