# Running efficient statistical analyses {#sec-statistical-analyses}

{{< include ../includes/_wip.qmd >}}

```{r setup}
#| include: false
library(tidyverse)
library(tidymodels)
load(here::here("data/lipidomics.rda"))
```

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Before beginning, get them to recall what they remember of the previous
session, either with something like Mentimeter or verbally. Preferably
something like Mentimeter because it allows everyone to participate, not
just the ones who are more comfortable being vocal to the whole group.
:::

TODO: intro here

## Learning objectives

The overall objective for this session is to:

1.  Describe the basic framework underlying most statistical analyses
    and use R to generate statistical results using this framework.

More specific objectives are to:

1.  Describe the general "workflow" and steps involved in stating the
    research question, constructing a model to help answer the question,
    preparing the data to match the requirements of the model, fitting
    it to the data, and finally extracting the results from the fitted
    model.
2.  Categorize the model definition step as a distinct, theory-driven
    step, separate from the data, and use `{parsnip}` functions to help
    with defining your model.
3.  Identify various data transformation techniques and evaluate which
    are good options given the data. Use functions in the `{recipes}`
    package to apply these transformations to your data.
4.  Recall principles of functional programming and apply them to
    running statistical analyses by using the `{purrr}` package.
5.  Use the `{broom}` package to extract the model results to later
    present them in tabular (with `knitr::kable()`) or graphical format
    (with `{ggplot2}`).
6.  Describe what a resampling technique is, the types available, and
    why it can help estimate the variability of model results. Apply
    functions from `{rsample}` to use these techniques.
7.  Continue applying the concepts and functions used from the previous
    sessions.

Specific "anti"-objectives:

-   Will **not** know how to choose and apply the appropriate
    statistical model or test, nor understand any statistical theory,
    nor interpret the statistical results correctly, nor determine the
    relevant data transformations for the statistical approach. What we
    show, we show *only as demonstration purposes only*, they could be
    entirely wrong in how to do them correctly if an expert were to
    review them.

## Exercise: What does a "model" mean?

> Time: \~8 minutes.

In science and especially statistics, we talk a lot about "models". But
what does model actually mean? What different types of definitions can
you think of? Is there a different understanding of model in statistics
compared to other areas?

1.  Take 1 minute to think about your understanding of a model.
2.  Then, over the next 4 minutes, discuss with your neighbour about the
    meaning of "model" and see if you can come to a shared
    understanding.
3.  Finally, over the next 3 minutes, we will share all together what a
    model is in the context of data analysis.

## Theory and "workflow" on statistical modeling

-   theory behind running analyses

    -   caveats: Each statistical method requires knowledge on it and on
        the underlying data, which we are **not** able to cover in this
        course, as that is highly specific to the problem and field of
        research.
        -   For instance, in this dataset, we would need someone
            familiar with omics to help us interpret what the data means
            and how to prepare it properly.
    -   Several steps:
        -   Diagram of these steps involved
        -   research question, broken down into a specific form
            -   Something influences something, adjusting for or
                considering other somethings.
        -   model specs
        -   processing
        -   fitting model to data
        -   extract results from fitted model
        -   present results

-   List some basic questions

-   What are some pipeline targets related to building model?

    -   All results generated (to use as dependencies of the other two)
    -   Table of specific results of statistical analysis
    -   Plot of specific results of statistical analysis

## Defining the model

-   Basic model:

    -   Outcome: CT vs T1D
    -   Predictors: lipidomics
    -   Covariates: age, gender
    -   diagram of relationship

first, subset data so only have one metabolite.

-   logistic regression

-   why tidymodels

-   diagram of tidymodels separation

    -   model definition
    -   transformation recipe
    -   data itself, along with formula

-   parsnip

    -   https://parsnip.tidymodels.org/reference/index.html#models
    -   https://parsnip.tidymodels.org/articles/Examples.html

```{r}
log_reg_specs <- logistic_reg() %>% 
  set_engine("glm")
```

## Exercise: How would you define a linear regression with parsnip?

> Time: \~10 minutes.

Using [parsnip's "Examples"
vignette](https://parsnip.tidymodels.org/articles/Examples.html) as well
as the code we wrote for the logistic regression above as a template,
write `{parsnip}` code that would define a simple (an engine of`"lm"`)
linear regression model. Begin by making a new Markdown header and code
chunk at the bottom of the `doc/lesson.Rmd` file, like listed below:

    ## Exercises
    ### Linear regression model definition

    ```{{r}}

    ```

After writing the code, run `r run_styler_text`. We will eventually
delete these exercise text in the R Markdown file, but for now, commit
the changes to the Git history.

```{r solution-define-linear-reg-model}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
linear_reg_specs <- linear_reg() %>% 
  set_engine("lm")
```

## Data transformations specific to modeling

-   Some problems:

    -   we have three cholesterol values
    -   values all have different ranges, will be an issue for
        interpreting model estimates across metabolites
    -   long data format

```{r}
library(tidyverse)
load(here::here("data/lipidomics.rda"))
lipidomics %>%
  count(code, metabolite) %>%
  filter(n > 1)
```

```{r}
lipidomics_wide <- lipidomics %>%
  mutate(metabolite = snakecase::to_snake_case(metabolite)) %>%
  pivot_wider(names_from = metabolite, values_from = value, values_fn = mean)
```

-   recipes

-   convenient with `recipes::step_impute_*` functions

recipes::step_naomit()

## Exercise: Which transformations make the most sense?

> Time: \~15 minutes.

Look at the list of `step_*` functions below and use the `?` or F1
(while having the cursor on the function name) to access the help
documentation. Consider the metabolite data in the `lipidomics` dataset.
Which of these transformations might you use?

```{r list-step-transforms}
#| eval: false
recipes::step_log()
recipes::step_scale()
recipes::step_normalize()
recipes::step_center()
recipes::step_sqrt()
```

-   With your neighbour (or group), justify which `step_` transformation
    you might use for the numeric metabolite data.
-   In the last 2 minutes of the exercise, we will all share our
    thoughts.

::: callout-note
The `step_` function we use in the text of this website in later
sections may be different from what you decide on in your group and in
the class as a whole. There isn't strictly a "right" answer here, since
it would ultimately require domain expertise in both lipidomic
quantification and statistical analysis of -omic data. But we ultimate
need to show and use *something* in the text.
:::

## Creating a transformation "recipe"

## Fitting the model by combining the recipe, model definition, and data

```{r}
workflows::workflow()
```

## Exercise: Run model with a different metabolite

> Time: \~10 minutes.

Try running the same model workflow but run the model with
`lipid_ch_3_1` instead of `cholesterol`.

1.  In the `doc/lesson.Rmd` file, create a new `###` header and code
    chunk at the bottom of the R Markdown file (see the scaffold
    template below).
2.  Start with creating a new data frame (call it `df_lipid_ch_3_1`),
    `select()`ing `class`, `gender`, `age`, and `lipid_ch_3_1`.
3.  Copy and paste the previous recipe `recipe_specs` we created above
    and then replace all `cholesterol` with `lipid_ch_3_1`.
4.  Copy and paste the same `model_workflow` code we created above,
    re-using both the same `log_reg_specs` in the `add_model()` function
    and `recipe_specs` (the one you modified in the task above) in the
    `add_recipe()` function.
5.  Run `fit()` on the `model_workflow`, making sure to use the
    `df_lipid_ch_3_1` in the `data` argument.
6.  Run the `fitted_model` in the Console to get the output results.
    What is the coefficient for the `lipid_ch_3_1` compared to the
    `cholesterol` result?
7.  Use `r run_styler_text` on the R Markdown file. Then commit the
    changes to the Git history.

Use the scaffolding below as a guide. *Note*: The code has been
purposefully written poorly so you can use `{styler}` to fix it up.

    ### Model with a different metabolite
    ``` {{r}}
    ___ <- lipidomics_wide%>%select(___,___,___,___)

    recipe_specs<-recipe(class ~ ___ +age+gender, 
    data = ___) %>% 
      step_normalize(___)

    model_workflow <- workflow()%>% ___(___) %>% 
      ___(___)
      
    fitted_model <- fit(model_workflow,data=___)
      fitted_model
    ```

```{r solution-model-with-different-metabolite}
#| eval: false
#| code-fold: true
#| code-summary: "**Click for the solution**. Only click if you are struggling or are out of time."
df_lipid_ch_3_1 <- lipidomics_wide %>% 
  select(class, gender, age, lipid_ch_3_1)

recipe_specs <- recipe(class ~ lipid_ch_3_1 + age + gender, data = df_lipid_ch_3_1) %>% 
  step_normalize(lipid_ch_3_1)

model_workflow <- workflow() %>% 
  add_model(log_reg_specs) %>% 
  add_recipe(recipe_specs)
  
fitted_model <- fit(model_workflow, data = df_lipid_ch_3_1)
fitted_model
```

<!-- TODO: Do I need to purl this at this point? Or only later as a function? -->

## Extracting results from the fitted models

-   broom

    -   tidy
    -   augment?

## Exercise: How would we use functional programming to run multiple models?

> Time: \~15 minutes.

-   Review functional programming from the intermediate course

-   explain how we can use functional programming to apply the model to
    each metabolite. Don't look ahead!

::: {.callout-note appearance="minimal" collapse="true"}
## Instructor note

Draw this out on a whiteboard or something.
:::

## Apply logistic regression to each metabolite

```{r}
lipidomics %>% 
  filter(metabolite == "Lipid -CH2-") %>% 
  ggplot(aes(x = value, fill = class)) +
  geom_dotplot(binwidth = 10)
```

## Determine variability in model estimates with resampling

-   rsamples with plotting of each estimates

-   Use bootstrap, but mention vfold_cv

## Exercise: Running multiple models by metabolite *and* re-sampled bootstrapped set

## Visualizing the variability of results

-   Combine augment with rsamples and ggplot2 to plot different
    estimates

```{r}
#| eval: false
lipidomics %>%
  # Deal with multiple cholesterols?
  # group_by(code, gender, age, class, metabolite) %>%
  # # .groups = "drop" to remove group_by structure, so we don't need to use ungroup
  # summarise(value = mean(value), .groups = "drop") %>%
  mutate(metabolite = snakecase::to_snake_case(metabolite)) %>%
  group_split(metabolite) 
  # map(~pivot_wider(.x, names_from = metabolite, values_from = value, values_fn = mean))
  
```

## Exercise: Convert model building code into functions for targets

## Summary
